import json
import os
import random

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, accuracy_score
from sklearn.model_selection import train_test_split
import joblib

DATA_PATHS = ["dataset_5000.json", "dataset_10000.json"]
MODEL_PATH = "sentiment_tfidf_logreg.joblib"

# ===== 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ =====
data = []
for path in DATA_PATHS:
    if not os.path.exists(path):
        print(f"‚ö†Ô∏è –§–∞–π–ª {path} –Ω–µ –Ω–∞–π–¥–µ–Ω, –ø—Ä–æ–ø—É—Å–∫–∞—é")
        continue
    with open(path, "r", encoding="utf-8") as f:
        part = json.load(f)
        data.extend(part)

print(f"–í—Å–µ–≥–æ –ø—Ä–∏–º–µ—Ä–æ–≤ –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏: {len(data)}")

texts = [item["text"] for item in data]
labels = [item["label"] for item in data]

# ===== 2. –ü–µ—Ä–µ–º–µ—à–∏–≤–∞–µ–º –∏ —Å–æ–∑–¥–∞—ë–º train/valid/test =====
train_texts, temp_texts, train_labels, temp_labels = train_test_split(
    texts, labels, test_size=0.2, random_state=42, shuffle=True
)

val_texts, test_texts, val_labels, test_labels = train_test_split(
    temp_texts, temp_labels, test_size=0.5, random_state=42, shuffle=True
)

print(f"Train: {len(train_texts)}, Validation: {len(val_texts)}, Test: {len(test_texts)}")

# ===== 3. Pipeline: TF-IDF + Logistic Regression =====
pipeline = Pipeline([
    ("tfidf", TfidfVectorizer(
        ngram_range=(1, 2),       # —É–Ω–∏–≥—Ä–∞–º–º—ã + –±–∏–≥—Ä–∞–º–º—ã
        max_features=100000,       # —É–≤–µ–ª–∏—á–∏–ª –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö
        sublinear_tf=True,         # —É–ª—É—á—à–µ–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤–∞
    )),
    ("clf", LogisticRegression(
        max_iter=500,
        n_jobs=-1,                 # –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å–µ CPU —è–¥—Ä–∞
        C=2.0,                     # –Ω–µ–º–Ω–æ–≥–æ —Å–∏–ª—å–Ω–µ–µ —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è
    )),
])

# ===== 4. –û–±—É—á–µ–Ω–∏–µ =====
print("–û–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏...")
pipeline.fit(train_texts, train_labels)

# ===== 5. –û—Ü–µ–Ω–∫–∞ (Validation) =====
print("\nüìä Validation results:")
val_preds = pipeline.predict(val_texts)
print(classification_report(val_labels, val_preds))

# ===== 6. –§–∏–Ω–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ (Test) =====
print("\nüß™ Test results:")
test_preds = pipeline.predict(test_texts)
print(classification_report(test_labels, test_preds))

# ===== 7. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ =====
joblib.dump(pipeline, MODEL_PATH)
print(f"\n‚úÖ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –≤ {MODEL_PATH}")
